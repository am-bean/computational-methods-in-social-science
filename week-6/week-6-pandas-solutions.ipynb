{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "80ac79ca-a0ef-4081-a14b-42ec81ce898f",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": null
    },
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "# Week 6: File I/O, Filtering, and Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d9c467b0-446d-4028-aa67-d2feb87132ca",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 18
    },
    "deepnote_cell_height": 226,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Learning to use the ‘pandas‘ Python library\n",
    "\n",
    "In this notebook we use the `pandas` python library to perform file input and output and to filter and organize our data. We have used `pandas` in every lecture so far without going into much detail because the functions it provides are too helpful to wait until Week 6. `pandas` is one of the most widely used python packages because it makes it easy to perform a large number of standard operations with tables of data. The library is extremely well documented with tutorials: https://pandas.pydata.org/docs/getting_started/index.html\n",
    "\n",
    "From this point forward, we will be working with a single dataset which we will progressively transform, analyse and visualise from Week 6 to Week 9. That dataset is the combined comment sections of two Reddit posts collected using the `praw` API that we saw in Week 2. The first post is about cloning [wooly mammoths](https://www.reddit.com/r/technology/comments/10py29t/scientists_are_reincarnating_the_woolly_mammoth/), and the second is about [remote work](https://www.reddit.com/r/technology/comments/10plq1f/remote_work_hasnt_actually_saved_americans_much/). The notebook I used to download the data into a file is available on Canvas, though you are welcome to just use the JSON file provided.\n",
    "\n",
    "This week, we will do some basic filtering and slicing to get an idea of what the dataset is like. We will also learn about using regular expressions, often called `regex`, to perform more general searches of text. Finally, we will save the data into a new file which we will start from next week.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cell_id": "5efbed6a-e825-4b2a-8bda-7cc4f2671139",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 24
    },
    "deepnote_cell_height": 99,
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3020,
    "execution_start": 1646038770920,
    "source_hash": "a933caac",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Run this cell to install the pandas library using the Python package manager pip\n",
    "# You probably already have pandas as it comes with Anaconda by default\n",
    "!pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "cell_id": "c52acc9e-91b3-49d7-b54a-a85bb87fd2c7",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 30
    },
    "deepnote_cell_type": "code",
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 0,
    "execution_start": 1646038773946,
    "source_hash": "f6cb1ae6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "d1d9a692-23b9-4e5a-8eb2-6720ecde63f5",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 6
    },
    "deepnote_cell_height": 70,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "## Reading and Writing Files\n",
    "\n",
    "As you've seen in the other classes already, web data can come in a variety of formats. We've already dealt with JSON, CSV, and HTML files, which are the ones you will run into most frequently with internet data. These file types tell you something about the way the information within them is stored, which allows a computer to know how to read that information back into a form Python can use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### JSON\n",
    "\n",
    "JSON stands for JavaScript Object Notation. It is a simple file type in which the data is stored as a string which is readable in any text editor. JSON files look very similar to Python dictionaries, and follow four basic rules. Every time there is an object with some set of attributes, it is enclosed in curly brackets `{}`. The attributes of the object are stored as key:value pairs separated by a colon, with commas between attributes. When an attribute takes a list as the value, the list is enclosed in square brackets `[]`. These rules can be combined and repeated to form very large objects, but a small one is shown below. Reading and writing JSON files can be done with the base Python libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_example = {\"key\": \"value\", \"key2\": [\"value\", \"value\", \"value\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Exercise 0.1:** Write a JSON file from the dictionary above, and then read it back again. Call the file `test.json`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard way to read and write files in python is to start by getting a file. Use `with open(filename, mode) as variable:`\n",
    "to create a variable where you can access the file. `with` is a special helper function for opening files that makes sure they close when you're done and don't get corrupted (or at least tries to). The value you give for `mode`, in this case `w` controls what you can do with the file. The table below shows the options for the mode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "| mode (name)             | Function | \n",
    "|:------------------------|:------------|\n",
    "| `w` (write)             | Open (or create and open) the file, erase any contents, and write new data |                    \n",
    "| `a` (append)            | Open (or create and open) the file, keep any contents, and write new data  |\n",
    "| `r` (read)              | Open the file and read the contents. Fails if the file does not exist|\n",
    "| `x` (create)            | Create a new file. Fails if the file already exists|\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first we create and write to the file\n",
    "with open(\"test.json\", \"w\") as f:\n",
    "    # json.dump takes a variable and writes it to the file given in the second argument\n",
    "    json.dump(json_example, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we read it back using very similar code\n",
    "with open(\"test.json\", \"r\") as f:\n",
    "    json_loaded = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# To check if it worked, see if our loaded data matches what we saved!\n",
    "json_loaded == json_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CSV\n",
    "\n",
    "CSV stands for Comma Separated Values. It is a simple file type in which the data is stored as a string which is readable in any text editor. CSV files are the basic version of Excel files, and are used for tabular data. As you might guess, the values are separated by commas. The only other rule is that new rows are written on new lines of the file. Sometimes, the first row has headers and the first column has row labels. If so, you can tell `pandas` to use these as row and/or column labels.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Exercise 0.2:** Write a CSV file from the dataframe below, and then read it back again. Call the file `test.csv`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>value</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0  value\n",
       "1  value\n",
       "2  value"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_example = pd.DataFrame(['value','value','value'])\n",
    "csv_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas does all the work for us\n",
    "# the only trick here is that since we don't care about the dataframe index, we don't save it\n",
    "\n",
    "with open('test.csv', 'w') as f:\n",
    "    csv_example.to_csv(f, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pandas does all the work for us\n",
    "\n",
    "with open('test.csv', 'r') as f:\n",
    "    csv_loaded = pd.read_csv(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>value</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0\n",
       "0  value\n",
       "1  value\n",
       "2  value"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking that we got the same thing as before\n",
    "csv_loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TXT\n",
    "\n",
    "Text files are extremely simple files. They contain text written out in plain form. You can store JSON or CSV files as TXT files, but there isn't usually a good reason to since the other file types provide more detail on how to read them back. The nice thing about txt files is that you can write anything that can be stored as as string. Therefore, you can build your own file types on top of txt files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Exercise 0.3:** Write a txt file from the string below, and then read it back again. Call the file `test.txt`.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "txt_example = \"value\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you use a with block you can just use f.write to add a string\n",
    "with open('text.txt','w') as f:\n",
    "    f.write(txt_example)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f.read returns everything in the file as a string\n",
    "# if that is too much data there are methods for going in shorter pieces\n",
    "with open('text.txt','r') as f:\n",
    "    txt_loaded = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that it worked\n",
    "txt_example == txt_loaded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "11bb52c8-ad91-4153-ad78-92d5590e6f47",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 72
    },
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Exercise 1: Loading our Reddit data from JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "210db550-fe4d-4e4f-a250-da92c07137d1",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 78
    },
    "deepnote_cell_height": 229.8000030517578,
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Exercise 1.1:** Use the methods we have just demonstrated to read our JSON data from the file. Store it as a dictionary for now.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('reddit_data.json','r') as f:\n",
    "    reddit_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['10py29t', '10plq1f'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# if you succeeded, you should have a dicitonary with two keys:\n",
    "# ['10py29t', '10plq1f']\n",
    "# these are the IDs of the Reddit posts we are using\n",
    "\n",
    "reddit_data.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Exercise 1.1a:</b> What data do we have about each post?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['title', 'created_at', 'id', 'permalink', 'num_comments', 'score', 'upvote_ratio', 'external_link', 'comments'])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data['10py29t'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Exercise 1.1b:</b> What data do we have about each comment?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['body', 'created_at', 'id', 'parent', 'score'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reddit_data['10py29t']['comments'][0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "<b>Exercise 1.1c:</b> Now we can see how many comments we have:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "cell_id": "9196af2b-8eb8-4320-96c3-60ac9607938a",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 90
    },
    "deepnote_cell_height": 111.69999694824219,
    "deepnote_cell_type": "code",
    "deepnote_output_heights": [
     21.1875
    ],
    "deepnote_to_be_reexecuted": false,
    "execution_millis": 3,
    "execution_start": 1645985832700,
    "source_hash": "efa21cb7",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Post 10py29t has 915 comments.\n",
      "Post 10plq1f has 817 comments.\n"
     ]
    }
   ],
   "source": [
    "# Using what you know about navigating dictionaries, find the comments under each key and count them\n",
    "for key in reddit_data.keys():\n",
    "    print(f'Post {key} has {len(reddit_data[key][\"comments\"])} comments.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pandas\n",
    "\n",
    "Now that we have the data into a dictionary, let's start to talk about `pandas`. Pandas comes from the words PANel DAta, a term from economics used for time-series data. It was originally started at a hedge fund, so at least one good thing has come out of quantitative finance. Because of the focus on time series, pandas has two main types of data, `Series` and `DataFrame`. A `Series` is a single column of data with an index, originally a series of observations of a single variable at different points in time. A `DataFrame` is a collection of `Series` which share an index, making what resembles a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x    1\n",
       "y    2\n",
       "z    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# here is a simple series\n",
    "series_example = pd.Series([1,2,3], index = ['x','y','z'])\n",
    "series_example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b  c\n",
       "x  1  2  3\n",
       "y  4  5  6\n",
       "z  7  8  9"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# and a simple dataframe\n",
    "df_example = pd.DataFrame([[1,2,3],[4,5,6],[7,8,9]], columns=['a','b','c'],  index = ['x','y','z'])\n",
    "df_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each series (column) in a dataframe has a name which can be read across the top of the dataframe (a,b,c in the example above). The left hand column is called the `index` and is shared across all the series in the dataframe. Entries in a series or dataframe can be accessed in several ways:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info alert\">\n",
    "\n",
    "**Example 2.0:** Several ways to access a series or dataframe are shown below:\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by the index in a series\n",
    "series_example[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by the index values using .loc\n",
    "series_example.loc['x']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# by the position in the series using .iloc\n",
    "series_example.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x    1\n",
       "z    3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# with booleans indicating which values to include\n",
    "# this requires one boolean per row\n",
    "\n",
    "series_example[[True, False, True]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x    1\n",
      "y    2\n",
      "dtype: int64\n",
      "x    1\n",
      "y    2\n",
      "dtype: int64\n",
      "y    2\n",
      "z    3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# all of these also accept lists of entries or slices as with python lists\n",
    "\n",
    "print(series_example[0:2])\n",
    "\n",
    "print(series_example.loc[['x','y']])\n",
    "\n",
    "print(series_example.iloc[1:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# Similarly, DataFrames can be accessed using most of these methods, but require both rows and columns:\n",
    "# rows come before columns\n",
    "print(df_example.loc['x','a'])\n",
    "\n",
    "# you can only use positional indices with iloc\n",
    "# this won't work df_example[0,0]\n",
    "print(df_example.iloc[0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x    1\n",
      "y    4\n",
      "Name: a, dtype: int64\n",
      "x    2\n",
      "y    5\n",
      "z    8\n",
      "Name: b, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# and you can mix and match slices and indices\n",
    "\n",
    "print(df_example.loc[['x','y'],'a'])\n",
    "\n",
    "print(df_example.iloc[0:3,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info alert\">\n",
    "\n",
    "**Example 2.1:** Now try it yourself. Find the largest element in the `example_series` and `example_df` using each of the methods shown above. Then for the dataframe, find the row and column with the largest sum.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n",
      "3\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# for the series\n",
    "print(series_example[2])\n",
    "print(series_example.loc['z'])\n",
    "print(series_example.iloc[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "# for the df\n",
    "print(df_example.loc['z','c'])\n",
    "print(df_example.iloc[2,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x    3\n",
      "y    6\n",
      "z    9\n",
      "Name: c, dtype: int64\n",
      "a    7\n",
      "b    8\n",
      "c    9\n",
      "Name: z, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# for the row and column\n",
    "print(df_example.loc[:,'c'])\n",
    "print(df_example.loc['z',:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Booleans\n",
    "\n",
    "The most powerful way to use the filtering and slicing is with logical statements. Since we can extract elements of a series or dataframe based on booleans, if we can create boolean series of what we want, it is easy to access. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info alert\">\n",
    "\n",
    "**Example 3.0:** If we want to find the even numbers in a series, we can first make a filter for which numbers are even, and then apply it to the series:\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x    False\n",
       "y     True\n",
       "z    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evens_filter = series_example %2 == 0 \n",
    "evens_filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "series_example[evens_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "y    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# typically you will see this done in a single step:\n",
    "series_example[series_example%2 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>y</th>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b  c\n",
       "y  4  5  6"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# you might also want to know the values in the other columns of a dataframe when a condition is true in the first column\n",
    "\n",
    "df_example[df_example['a']%2==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info alert\">\n",
    "\n",
    "**Example 3.1:** Find the rows of the `df_example` where the entry in column `b` is even.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>x</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>z</th>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   a  b  c\n",
       "x  1  2  3\n",
       "z  7  8  9"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_example[df_example['b']%2==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: Loading our Reddit data into Pandas and filtering it\n",
    "\n",
    "Using the skills we've just covered, we want to load our dictionary of Reddit data into a pandas dataframe with one row per comment and columns for each propety of the comments. Also include a column for the post to which the comment is responding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info alert\">\n",
    "\n",
    "**Excercise 2.1:** Convert the `reddit_data` dictionary into a dataframe\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you'll want to start with an empty list\n",
    "reddit_comments = []\n",
    "\n",
    "# loop over the two posts\n",
    "for key in reddit_data.keys():\n",
    "    # loop over the comments in the posts\n",
    "    for comment in reddit_data[key]['comments']:\n",
    "        # add an entry for which post it came from\n",
    "        comment['post'] = key\n",
    "        # add the comment to the list of all comments\n",
    "        reddit_comments.append(comment)\n",
    "\n",
    "# convert to a dataframe and cleanup the datetime\n",
    "reddit_df = pd.DataFrame(reddit_comments)\n",
    "reddit_df['created_at'] = pd.to_datetime(reddit_df['created_at'], unit='s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1732, 6)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can see how many rows and columns there are. There should be one row per comment, 915 + 817 = 1732\n",
    "reddit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>parent</th>\n",
       "      <th>score</th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when you say it like that - gimme 2</td>\n",
       "      <td>2023-02-01 07:42:00</td>\n",
       "      <td>j6r1s1s</td>\n",
       "      <td>t1_j6qxv18</td>\n",
       "      <td>6</td>\n",
       "      <td>10py29t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mammork?\\n\\nI would that make them hammoths?</td>\n",
       "      <td>2023-02-01 10:18:59</td>\n",
       "      <td>j6rd2o8</td>\n",
       "      <td>t1_j6qxv18</td>\n",
       "      <td>3</td>\n",
       "      <td>10py29t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mmmmmmmm mammoth pork</td>\n",
       "      <td>2023-02-01 06:52:37</td>\n",
       "      <td>j6qxv18</td>\n",
       "      <td>t1_j6obhxv</td>\n",
       "      <td>22</td>\n",
       "      <td>10py29t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It’ll just be made from pressed pork.</td>\n",
       "      <td>2023-01-31 19:16:08</td>\n",
       "      <td>j6obhxv</td>\n",
       "      <td>t1_j6notr0</td>\n",
       "      <td>68</td>\n",
       "      <td>10py29t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11 years before they’re extinct again</td>\n",
       "      <td>2023-02-01 06:51:58</td>\n",
       "      <td>j6qxt2e</td>\n",
       "      <td>t1_j6notr0</td>\n",
       "      <td>7</td>\n",
       "      <td>10py29t</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           body          created_at       id  \\\n",
       "0           when you say it like that - gimme 2 2023-02-01 07:42:00  j6r1s1s   \n",
       "1  Mammork?\\n\\nI would that make them hammoths? 2023-02-01 10:18:59  j6rd2o8   \n",
       "2                         Mmmmmmmm mammoth pork 2023-02-01 06:52:37  j6qxv18   \n",
       "3         It’ll just be made from pressed pork. 2023-01-31 19:16:08  j6obhxv   \n",
       "4         11 years before they’re extinct again 2023-02-01 06:51:58  j6qxt2e   \n",
       "\n",
       "       parent  score     post  \n",
       "0  t1_j6qxv18      6  10py29t  \n",
       "1  t1_j6qxv18      3  10py29t  \n",
       "2  t1_j6obhxv     22  10py29t  \n",
       "3  t1_j6notr0     68  10py29t  \n",
       "4  t1_j6notr0      7  10py29t  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we also seem to have all of the columns we wanted\n",
    "reddit_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info alert\">\n",
    "\n",
    "**Excercise 2.2:** Now that we've made the dataframe, let's filter it based on:\n",
    "- which post it came from\n",
    "-when the comment was made\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>parent</th>\n",
       "      <th>score</th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when you say it like that - gimme 2</td>\n",
       "      <td>2023-02-01 07:42:00</td>\n",
       "      <td>j6r1s1s</td>\n",
       "      <td>t1_j6qxv18</td>\n",
       "      <td>6</td>\n",
       "      <td>10py29t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mammork?\\n\\nI would that make them hammoths?</td>\n",
       "      <td>2023-02-01 10:18:59</td>\n",
       "      <td>j6rd2o8</td>\n",
       "      <td>t1_j6qxv18</td>\n",
       "      <td>3</td>\n",
       "      <td>10py29t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mmmmmmmm mammoth pork</td>\n",
       "      <td>2023-02-01 06:52:37</td>\n",
       "      <td>j6qxv18</td>\n",
       "      <td>t1_j6obhxv</td>\n",
       "      <td>22</td>\n",
       "      <td>10py29t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>It’ll just be made from pressed pork.</td>\n",
       "      <td>2023-01-31 19:16:08</td>\n",
       "      <td>j6obhxv</td>\n",
       "      <td>t1_j6notr0</td>\n",
       "      <td>68</td>\n",
       "      <td>10py29t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11 years before they’re extinct again</td>\n",
       "      <td>2023-02-01 06:51:58</td>\n",
       "      <td>j6qxt2e</td>\n",
       "      <td>t1_j6notr0</td>\n",
       "      <td>7</td>\n",
       "      <td>10py29t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>910</th>\n",
       "      <td>“The World Poaching Association in a press rel...</td>\n",
       "      <td>2023-02-01 13:05:13</td>\n",
       "      <td>j6rrmwl</td>\n",
       "      <td>t3_10py29t</td>\n",
       "      <td>1</td>\n",
       "      <td>10py29t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>911</th>\n",
       "      <td>Our hunting practices probably made them go ex...</td>\n",
       "      <td>2023-02-01 13:26:41</td>\n",
       "      <td>j6ru3om</td>\n",
       "      <td>t3_10py29t</td>\n",
       "      <td>1</td>\n",
       "      <td>10py29t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>912</th>\n",
       "      <td>Why?</td>\n",
       "      <td>2023-02-01 13:35:55</td>\n",
       "      <td>j6rv81a</td>\n",
       "      <td>t3_10py29t</td>\n",
       "      <td>1</td>\n",
       "      <td>10py29t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>913</th>\n",
       "      <td>Did Jurassic Park teach us nothing? 😂</td>\n",
       "      <td>2023-02-01 14:23:26</td>\n",
       "      <td>j6s1ib8</td>\n",
       "      <td>t3_10py29t</td>\n",
       "      <td>1</td>\n",
       "      <td>10py29t</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>Seemed to work well in star wars for a while a...</td>\n",
       "      <td>2023-02-01 15:11:12</td>\n",
       "      <td>j6s8irm</td>\n",
       "      <td>t3_10py29t</td>\n",
       "      <td>1</td>\n",
       "      <td>10py29t</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>915 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  body          created_at  \\\n",
       "0                  when you say it like that - gimme 2 2023-02-01 07:42:00   \n",
       "1         Mammork?\\n\\nI would that make them hammoths? 2023-02-01 10:18:59   \n",
       "2                                Mmmmmmmm mammoth pork 2023-02-01 06:52:37   \n",
       "3                It’ll just be made from pressed pork. 2023-01-31 19:16:08   \n",
       "4                11 years before they’re extinct again 2023-02-01 06:51:58   \n",
       "..                                                 ...                 ...   \n",
       "910  “The World Poaching Association in a press rel... 2023-02-01 13:05:13   \n",
       "911  Our hunting practices probably made them go ex... 2023-02-01 13:26:41   \n",
       "912                                               Why? 2023-02-01 13:35:55   \n",
       "913              Did Jurassic Park teach us nothing? 😂 2023-02-01 14:23:26   \n",
       "914  Seemed to work well in star wars for a while a... 2023-02-01 15:11:12   \n",
       "\n",
       "          id      parent  score     post  \n",
       "0    j6r1s1s  t1_j6qxv18      6  10py29t  \n",
       "1    j6rd2o8  t1_j6qxv18      3  10py29t  \n",
       "2    j6qxv18  t1_j6obhxv     22  10py29t  \n",
       "3    j6obhxv  t1_j6notr0     68  10py29t  \n",
       "4    j6qxt2e  t1_j6notr0      7  10py29t  \n",
       "..       ...         ...    ...      ...  \n",
       "910  j6rrmwl  t3_10py29t      1  10py29t  \n",
       "911  j6ru3om  t3_10py29t      1  10py29t  \n",
       "912  j6rv81a  t3_10py29t      1  10py29t  \n",
       "913  j6s1ib8  t3_10py29t      1  10py29t  \n",
       "914  j6s8irm  t3_10py29t      1  10py29t  \n",
       "\n",
       "[915 rows x 6 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# First get all the mammoth posts\n",
    "reddit_df[reddit_df['post']=='10py29t']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>body</th>\n",
       "      <th>created_at</th>\n",
       "      <th>id</th>\n",
       "      <th>parent</th>\n",
       "      <th>score</th>\n",
       "      <th>post</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>915</th>\n",
       "      <td>I'm there where you were, in the elements and ...</td>\n",
       "      <td>2023-01-31 16:54:59</td>\n",
       "      <td>j6nobr5</td>\n",
       "      <td>t1_j6nneu9</td>\n",
       "      <td>2</td>\n",
       "      <td>10plq1f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>916</th>\n",
       "      <td>I was able to leverage my experience and the l...</td>\n",
       "      <td>2023-01-31 23:12:07</td>\n",
       "      <td>j6pd2pm</td>\n",
       "      <td>t1_j6p4jgg</td>\n",
       "      <td>2</td>\n",
       "      <td>10plq1f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>917</th>\n",
       "      <td>As someone who also does telecom installation ...</td>\n",
       "      <td>2023-01-31 22:15:51</td>\n",
       "      <td>j6p4jgg</td>\n",
       "      <td>t1_j6nneu9</td>\n",
       "      <td>2</td>\n",
       "      <td>10plq1f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>918</th>\n",
       "      <td>Hey man I get it. I spent nearly a decade inst...</td>\n",
       "      <td>2023-01-31 16:49:25</td>\n",
       "      <td>j6nneu9</td>\n",
       "      <td>t1_j6nerw8</td>\n",
       "      <td>6</td>\n",
       "      <td>10plq1f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>When you apply to WFH jobs, be reasonable, but...</td>\n",
       "      <td>2023-01-31 22:08:51</td>\n",
       "      <td>j6p3go5</td>\n",
       "      <td>t1_j6nerw8</td>\n",
       "      <td>2</td>\n",
       "      <td>10plq1f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1727</th>\n",
       "      <td>Show this to your employer when they try to br...</td>\n",
       "      <td>2023-02-01 14:24:01</td>\n",
       "      <td>j6s1le2</td>\n",
       "      <td>t3_10plq1f</td>\n",
       "      <td>1</td>\n",
       "      <td>10plq1f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1728</th>\n",
       "      <td>Are projects more successful working remotely ...</td>\n",
       "      <td>2023-02-01 14:51:21</td>\n",
       "      <td>j6s5iww</td>\n",
       "      <td>t3_10plq1f</td>\n",
       "      <td>1</td>\n",
       "      <td>10plq1f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1729</th>\n",
       "      <td>Business Insider is literal corporate trash.</td>\n",
       "      <td>2023-02-01 14:53:10</td>\n",
       "      <td>j6s5sx8</td>\n",
       "      <td>t3_10plq1f</td>\n",
       "      <td>1</td>\n",
       "      <td>10plq1f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1730</th>\n",
       "      <td>More money, less commute.</td>\n",
       "      <td>2023-02-01 15:15:14</td>\n",
       "      <td>j6s94yv</td>\n",
       "      <td>t3_10plq1f</td>\n",
       "      <td>1</td>\n",
       "      <td>10plq1f</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1731</th>\n",
       "      <td>This isn't a problem with a dedicated home off...</td>\n",
       "      <td>2023-02-01 15:38:10</td>\n",
       "      <td>j6scoq9</td>\n",
       "      <td>t3_10plq1f</td>\n",
       "      <td>1</td>\n",
       "      <td>10plq1f</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>817 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   body          created_at  \\\n",
       "915   I'm there where you were, in the elements and ... 2023-01-31 16:54:59   \n",
       "916   I was able to leverage my experience and the l... 2023-01-31 23:12:07   \n",
       "917   As someone who also does telecom installation ... 2023-01-31 22:15:51   \n",
       "918   Hey man I get it. I spent nearly a decade inst... 2023-01-31 16:49:25   \n",
       "919   When you apply to WFH jobs, be reasonable, but... 2023-01-31 22:08:51   \n",
       "...                                                 ...                 ...   \n",
       "1727  Show this to your employer when they try to br... 2023-02-01 14:24:01   \n",
       "1728  Are projects more successful working remotely ... 2023-02-01 14:51:21   \n",
       "1729       Business Insider is literal corporate trash. 2023-02-01 14:53:10   \n",
       "1730                          More money, less commute. 2023-02-01 15:15:14   \n",
       "1731  This isn't a problem with a dedicated home off... 2023-02-01 15:38:10   \n",
       "\n",
       "           id      parent  score     post  \n",
       "915   j6nobr5  t1_j6nneu9      2  10plq1f  \n",
       "916   j6pd2pm  t1_j6p4jgg      2  10plq1f  \n",
       "917   j6p4jgg  t1_j6nneu9      2  10plq1f  \n",
       "918   j6nneu9  t1_j6nerw8      6  10plq1f  \n",
       "919   j6p3go5  t1_j6nerw8      2  10plq1f  \n",
       "...       ...         ...    ...      ...  \n",
       "1727  j6s1le2  t3_10plq1f      1  10plq1f  \n",
       "1728  j6s5iww  t3_10plq1f      1  10plq1f  \n",
       "1729  j6s5sx8  t3_10plq1f      1  10plq1f  \n",
       "1730  j6s94yv  t3_10plq1f      1  10plq1f  \n",
       "1731  j6scoq9  t3_10plq1f      1  10plq1f  \n",
       "\n",
       "[817 rows x 6 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's get the others by filtering for `not mammoth posts`\n",
    "reddit_df[~(reddit_df['post']=='10py29t')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mammoth post had 4 comments in the first hour.\n",
      "The remote work post had 573 comments in the first hour.\n"
     ]
    }
   ],
   "source": [
    "# how many posts were made in the first hour of each post?\n",
    "\n",
    "# the mammoth post was made at Tuesday, January 31, 2023 12:42:36 PM\n",
    "# the remote work post was made at Tuesday, January 31, 2023 2:32:31 AM\n",
    " \n",
    "mammoth_date = datetime.strptime('31/01/23 13:42:36', '%d/%m/%y %H:%M:%S')\n",
    "remote_work_date = datetime.strptime('31/01/23 15:32:31', '%d/%m/%y %H:%M:%S')\n",
    "\n",
    "print(f\"The mammoth post had {len(reddit_df[(reddit_df['post'] == '10py29t') & (reddit_df['created_at'] < mammoth_date)])} comments in the first hour.\")\n",
    "\n",
    "print(f\"The remote work post had {len(reddit_df[~(reddit_df['post'] == '10py29t') & (reddit_df['created_at'] < remote_work_date)])} comments in the first hour.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info alert\">\n",
    "\n",
    "**Excercise 2.3:** We're planning to do sentiment analysis on the text in these comments. Do you notice anything in the comments below?\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19                                           You think? 🧐\n",
       "63      Offer it in the Natural History Museum's cafet...\n",
       "119     Breaking News 🚨 🚨 🚨\\n\\nWoolly Mammoth to be br...\n",
       "929     >I want this for everyone! \\n\\nToo bad only th...\n",
       "1157                          Take my poor woman's gold 🥇\n",
       "1457    Business Insider definitely wants you back in ...\n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# these might pose problems for us\n",
    "reddit_df['body'][[19,63,119,929,1157,1457]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info alert\">\n",
    "\n",
    "**Excercise 2.4:** For now, let's find all the rows with special characters in them and create a new column with a boolean label called `has_emoji`.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Regular Expressions\n",
    "\n",
    "To find emojis, we're going to use a special type of searching in strings called `regular expressions`. \"Regex\", as it is commonly called, is a standard language for expressing text searches which can be used across programming languages (and elsewhere like in Excel). Beyond what I will explain, an excellent in-depth tutorial is available here (https://regexone.com/).\n",
    "\n",
    "Regex uses pattern matching between a search string and a set of target strings. It can return either whether or not there was a match or what the match was if it existed. The most basic version is just like using `find` on your computer. If the thing you search is anywhere in the target string, it will match:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, False]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# searches for 'abc' in the target strings\n",
    "# the syntax is re.search('search expression', 'target expression')\n",
    "\n",
    "targets = ['abc123', '123abc', 'acb132']\n",
    "\n",
    "search = 'abc'\n",
    "\n",
    "[True if re.search(search, target) else False for target in targets] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next level of regex is `wildcards`. The `.` character matches anything. You can also have a list of options in square braces `[]`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, False]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# searches for a_c where _ can be any one character\n",
    "\n",
    "targets = ['aac', 'abc', 'abbc']\n",
    "\n",
    "search = 'a.c'\n",
    "\n",
    "[True if re.search(search, target) else False for target in targets] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False, False]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# searches for a_c where _ can be any one character from the set [abc]\n",
    "\n",
    "targets = ['aac', 'adc', 'abbc']\n",
    "\n",
    "search = 'a[abc]c'\n",
    "\n",
    "[True if re.search(search, target) else False for target in targets] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You might want to allow for more than one copy of a character or wildcard, or none at all. The `*` character matches zero or more repetitions, while the `+` character matches one or more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False, True]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# searches for a_c where _ can be any one or more character from the set [abc]\n",
    "\n",
    "targets = ['aac', 'adc', 'abbc']\n",
    "\n",
    "search = 'a[abc]+c'\n",
    "\n",
    "[True if re.search(search, target) else False for target in targets] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, False]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# searches for a_c where _ can be anything at all\n",
    "\n",
    "targets = ['aac', 'a$c', 'bbca']\n",
    "\n",
    "search = 'a.*c'\n",
    "\n",
    "[True if re.search(search, target) else False for target in targets] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can exclude characters using the `^` and `[]` in combination."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, True, False, True]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# searches for a_c where _ can be anything except `b`\n",
    "\n",
    "targets = ['aaac', 'a$c', 'abc', 'ac']\n",
    "\n",
    "search = 'a[^b]*c'\n",
    "\n",
    "[True if re.search(search, target) else False for target in targets] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two last things: sometimes you might want to match a character that already has a meaning (like `*`), then you use a `\\` to escape the character in question. Also, if you want to allow a range of characters, you can use a `-`. (This only works for alphanumerics). All of these features can be combined to match very complex things. https://www.explainxkcd.com/wiki/index.php/1313:_Regex_Golf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True, False, False]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# searches for a_c where _ can only be `*`\n",
    "\n",
    "targets = ['aaac', 'a$c', 'abc', 'ac']\n",
    "\n",
    "search = 'a\\$c'\n",
    "\n",
    "[True if re.search(search, target) else False for target in targets] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[True, False, True, False]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# searches for a_c where _ can be any set of at least one lowercase letter(s) \n",
    "\n",
    "targets = ['aaac', 'a$c', 'abc', 'ac']\n",
    "\n",
    "search = 'a[a-z]+c'\n",
    "\n",
    "[True if re.search(search, target) else False for target in targets] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info alert\">\n",
    "\n",
    "**Excercise 2.4a:** Create a regex search which matches `c_b_a` where `_` can be any one uppercase letter. \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, False, True, False]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets = ['cba', 'cBBbAa', 'cCbBa', 'ccbba']\n",
    "\n",
    "search = 'c[A-Z]b[A-Z]a'\n",
    "\n",
    "[True if re.search(search, target) else False for target in targets] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info alert\">\n",
    "\n",
    "**Excercise 2.4b:** Find a string which matches the regex below. (Hint: the name I used might help.)\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(0, 1), match='🧐'>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = \"🧐\"\n",
    "\n",
    "regex_nonstandard_chars = '''[^a-zA-Z0-9\\s\\-‘’“”'\"…:;?!.·,|/\\\\\\(\\)\\[\\]=≈\\*^+%&@°#$><—–~_]+'''\n",
    "\n",
    "re.search(regex_nonstandard_chars, target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info alert\">\n",
    "\n",
    "**Excercise 2.4c:** Using regex, find all the entries in `reddit_df` where the text includes an emoji.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        True\n",
       "1        True\n",
       "2        True\n",
       "3        True\n",
       "4        True\n",
       "        ...  \n",
       "1727     True\n",
       "1728    False\n",
       "1729     True\n",
       "1730    False\n",
       "1731     True\n",
       "Name: body, Length: 1732, dtype: bool"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pandas also has special behaviours for regex. rather than using re.search, we \n",
    "# use Series.str.contains('search string')\n",
    "\n",
    "reddit_df['body'].str.contains('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19                                           You think? 🧐\n",
       "63      Offer it in the Natural History Museum's cafet...\n",
       "119     Breaking News 🚨 🚨 🚨\\n\\nWoolly Mammoth to be br...\n",
       "138     We’ve had second extinction, but what about th...\n",
       "149     I'm crying I'm laughing so hard!!!! ...Now jus...\n",
       "162              Mfw a mammoth scolds me about politics 🦣\n",
       "167     That's interesting, I wonder if they were able...\n",
       "307                      Ayo we *breeding* raptors? 😳 /jk\n",
       "343                      We need more drowning mammoths 🦣\n",
       "473     Did we not learn anything from Jurassic Park?! 😳😬\n",
       "480       Lol, they can go roam freely in Antartica. 🦣🦣❄❄\n",
       "585     Bringing it back to a hot and getting hotter p...\n",
       "648     So we’re going to have mammoth steaks while th...\n",
       "683     Why do we fuck with things that shouldn’t be f...\n",
       "697     The forbidden hamburger meat. They couldn't se...\n",
       "717     Human stupidity at his maximum level. why not ...\n",
       "833     *sigh*…just because they could doesn’t mean th...\n",
       "843     Time to reclassify “Jurassic Park” as non-fict...\n",
       "855                                  Life finds a way … 🦕\n",
       "913                 Did Jurassic Park teach us nothing? 😂\n",
       "929     >I want this for everyone! \\n\\nToo bad only th...\n",
       "1000    10 hours a week*50 weeks=500 hours/year \\n\\nOv...\n",
       "1157                          Take my poor woman's gold 🥇\n",
       "1198    It's funny seeing the sheer panic on Reddit wh...\n",
       "1265                                Fuck them all too!\\n🤣\n",
       "1338                                   … says Elon Musk 👀\n",
       "1346    Let them think we actually work 8 hours and no...\n",
       "1451    👍 still better than being in an office regardless\n",
       "1457    Business Insider definitely wants you back in ...\n",
       "1463    As being an MD, I work day and night, at  home...\n",
       "1584    WFH is the best for certain jobs. \\nI slowly c...\n",
       "1642                                 Not this American 🇺🇸\n",
       "1667    Be nice if they had remote work for constructi...\n",
       "Name: body, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This uses my nonstandard characters regex to find the emoji\n",
    "\n",
    "reddit_df[reddit_df['body'].str.contains(regex_nonstandard_chars)]['body']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert-info alert\">\n",
    "\n",
    "**Excercise 2.5:** Add a column to `reddit_df` which indicates whether the body text of the comment contains an emoji.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df['has_emoji'] = reddit_df['body'].str.contains(regex_nonstandard_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = '''Husband (38M) and I (39F) have been trying for a baby for around 2 years now. We've had various tests and my results have been fine but there are a couple of issues on his side. He's being very good and taking supplements etc but he keeps trying to push me down the ivf route.\n",
    "\n",
    "We've been to the clinic for tests and now the next step would be starting the procedure. I have said I am not comfortable with it. I have anxiety and quite frankly the thought of the whole process sends me into a panic attack. I am waking up with a racing heart every morning. I feel sick and unhappy. I feel like I'm walking on eggshells to avoid the conversation.\n",
    "\n",
    "I don't want to regret not having a child but at the same time I wish the whole thing would just go away.\n",
    "\n",
    "I don't know what to do. He says his mental health will be affected if we don't have a kid but mine is already affected now.\n",
    "\n",
    "Any advice?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'\\([0-9][0-9][MFmf]'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<re.Match object; span=(18, 25), match='I (39F)'>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = '[I] [\\(\\[][0-9][0-9][MFmf][\\)\\]]'\n",
    "\n",
    "re.search(search, sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_id": "f2cd8fc8-9b5f-4983-91d6-0764125f30f9",
    "deepnote_app_coordinates": {
     "h": 5,
     "w": 12,
     "x": 0,
     "y": 300
    },
    "deepnote_cell_type": "markdown",
    "tags": []
   },
   "source": [
    "### Exercise 3\n",
    "\n",
    "<div class=\"alert-info alert\">\n",
    "\n",
    "Split the `reddit_df` into two dataframes and save each one as a CSV file called `mammoths.csv` and `remote_work.csv`\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataframe\n",
    "mammoths_df = reddit_df[reddit_df['post']=='10py29t']\n",
    "remote_work_df = reddit_df[reddit_df['post']=='10plq1f']\n",
    "\n",
    "# save each dataframe\n",
    "mammoths_df.to_csv('mammoths.csv',index=False)\n",
    "remote_work_df.to_csv('remote_work.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "deepnote": {
   "is_reactive": false
  },
  "deepnote_app_layout": "article",
  "deepnote_execution_queue": [],
  "deepnote_notebook_id": "e14e0833-7f70-4764-8920-14303e12f9cc",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
